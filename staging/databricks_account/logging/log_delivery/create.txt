POST
/api/2.0/accounts/{account_id}/log-delivery
Creates a new Databricks log delivery configuration to enable delivery of the specified type of logs to your storage location. This requires that you already created a
credential object
(which encapsulates a cross-account service IAM role) and a
storage configuration object
(which encapsulates an S3 bucket).
For full details, including the required IAM role policies and bucket policies, see
Deliver and access billable usage logs
or
Configure audit logging
.
Note
: There is a limit on the number of log delivery configurations available per account (each limit applies separately to each log type including billable usage and audit logs). You can create a maximum of two enabled account-level delivery configurations (configurations without a workspace filter) per type. Additionally, you can create two enabled workspace-level delivery configurations per workspace for each log type, which means that the same workspace ID can occur in the workspace filter for no more than two delivery configurations per log type.
You cannot delete a log delivery configuration, but you can disable it (see
Enable or disable log delivery configuration
).
Path parameters
code: account_id
required
uuid
Databricks account ID of any type. For non-E2 account types, get your account ID from the
Accounts Console
.
Request body
Properties of the new log delivery configuration.
code: log_delivery_configuration
object
code: config_name
string
<= 255 characters
The optional human-readable name of the log delivery configuration. Defaults to empty.
code: status
string
Enum:
code: ENABLED | DISABLED
Status of log delivery configuration. Set to
code: ENABLED
(enabled) or
code: DISABLED
(disabled). Defaults to
code: ENABLED
. You can
enable or disable the configuration
later. Deletion of a configuration is not supported, so disable a log delivery configuration that is no longer needed.
code: log_type
required
string
Enum:
code: BILLABLE_USAGE | AUDIT_LOGS
Log delivery type. Supported values are:
code: BILLABLE_USAGE
— Configure
billable usage log delivery
. For the CSV schema, see the
View billable usage
.
code: AUDIT_LOGS
— Configure
audit log delivery
. For the JSON schema, see
Configure audit logging
code: output_format
required
string
Enum:
code: CSV | JSON
The file type of log delivery.
If
code: log_type
is
code: BILLABLE_USAGE
, this value must be
code: CSV
. Only the CSV (comma-separated values) format is supported. For the schema, see the
View billable usage
If
code: log_type
is
code: AUDIT_LOGS
, this value must be
code: JSON
. Only the JSON (JavaScript Object Notation) format is supported. For the schema, see the
Configuring audit logs
.
code: credentials_id
required
uuid
The ID for a method:credentials/create that represents the AWS IAM role with policy and trust relationship as described in the main billable usage documentation page. See
Configure billable usage delivery
.
code: storage_configuration_id
required
uuid
The ID for a method:storage/create  that represents the S3 bucket with bucket policy as described in the main billable usage documentation page. See
Configure billable usage delivery
.
code: workspace_ids_filter
Array of int64
Optional filter that specifies workspace IDs to deliver logs for. By default the workspace filter is empty and log delivery applies at the account level, delivering workspace-level logs for all workspaces in your account, plus account level logs. You can optionally set this field to an array of workspace IDs (each one is an
code: int64
) to which log delivery should apply, in which case only workspace-level logs relating to the specified workspaces are delivered.
If you plan to use different log delivery configurations for different workspaces, set this field explicitly. Be aware that delivery configurations mentioning specific workspaces won't apply to new workspaces created in the future, and delivery won't include account level logs.
For some types of Databricks deployments there is only one workspace per account ID, so this field is unnecessary.
code: delivery_path_prefix
string
The optional delivery path prefix within Amazon S3 storage. Defaults to empty, which means that logs are delivered to the root of the bucket. This must be a valid S3 object key. This must not start or end with a slash character.
code: delivery_start_time
string
2[0-9][0-9][0-9]-(0[1-9]|1[012])
This field applies only if
code: log_type
is
code: BILLABLE_USAGE
. This is the optional start month and year for delivery, specified in
code: YYYY-MM
format. Defaults to current year and month.
code: BILLABLE_USAGE
logs are not available for usage before March 2019 (
code: 2019-03
).
Responses
200
The log delivery configuration creation request succeeded.
The log delivery configuration creation request succeeded.
code: log_delivery_configuration
object
code: account_id
uuid
The Databricks account ID that hosts the log delivery configuration.
code: config_id
uuid
Databricks log delivery configuration ID.
code: creation_time
int64
Time in epoch milliseconds when the log delivery configuration was created.
code: update_time
int64
Time in epoch milliseconds when the log delivery configuration was updated.
code: log_delivery_status
object
Databricks log delivery status.
code: config_name
string
<= 255 characters
The optional human-readable name of the log delivery configuration. Defaults to empty.
code: status
string
Enum:
code: ENABLED | DISABLED
Status of log delivery configuration. Set to
code: ENABLED
(enabled) or
code: DISABLED
(disabled). Defaults to
code: ENABLED
. You can
enable or disable the configuration
later. Deletion of a configuration is not supported, so disable a log delivery configuration that is no longer needed.
code: log_type
string
Enum:
code: BILLABLE_USAGE | AUDIT_LOGS
Log delivery type. Supported values are:
code: BILLABLE_USAGE
— Configure
billable usage log delivery
. For the CSV schema, see the
View billable usage
.
code: AUDIT_LOGS
— Configure
audit log delivery
. For the JSON schema, see
Configure audit logging
code: output_format
string
Enum:
code: CSV | JSON
The file type of log delivery.
If
code: log_type
is
code: BILLABLE_USAGE
, this value must be
code: CSV
. Only the CSV (comma-separated values) format is supported. For the schema, see the
View billable usage
If
code: log_type
is
code: AUDIT_LOGS
, this value must be
code: JSON
. Only the JSON (JavaScript Object Notation) format is supported. For the schema, see the
Configuring audit logs
.
code: credentials_id
uuid
The ID for a method:credentials/create that represents the AWS IAM role with policy and trust relationship as described in the main billable usage documentation page. See
Configure billable usage delivery
.
code: storage_configuration_id
uuid
The ID for a method:storage/create  that represents the S3 bucket with bucket policy as described in the main billable usage documentation page. See
Configure billable usage delivery
.
code: workspace_ids_filter
Array of int64
Optional filter that specifies workspace IDs to deliver logs for. By default the workspace filter is empty and log delivery applies at the account level, delivering workspace-level logs for all workspaces in your account, plus account level logs. You can optionally set this field to an array of workspace IDs (each one is an
code: int64
) to which log delivery should apply, in which case only workspace-level logs relating to the specified workspaces are delivered.
If you plan to use different log delivery configurations for different workspaces, set this field explicitly. Be aware that delivery configurations mentioning specific workspaces won't apply to new workspaces created in the future, and delivery won't include account level logs.
For some types of Databricks deployments there is only one workspace per account ID, so this field is unnecessary.
code: delivery_path_prefix
string
The optional delivery path prefix within Amazon S3 storage. Defaults to empty, which means that logs are delivered to the root of the bucket. This must be a valid S3 object key. This must not start or end with a slash character.
code: delivery_start_time
string
2[0-9][0-9][0-9]-(0[1-9]|1[012])
This field applies only if
code: log_type
is
code: BILLABLE_USAGE
. This is the optional start month and year for delivery, specified in
code: YYYY-MM
format. Defaults to current year and month.
code: BILLABLE_USAGE
logs are not available for usage before March 2019 (
code: 2019-03
).
This method might return the following HTTP codes: 400, 401, 404, 500
Error responses are returned in the following format:
{
"error_code"
:
"Error code"
,
"message"
:
"Human-readable error message."
}
Possible error codes:
HTTP code
error_code
Description
401
UNAUTHORIZED
The request does not have valid authentication credentials for the operation.
500
INTERNAL_SERVER_ERROR
Internal error.